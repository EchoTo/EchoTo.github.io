<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>

    <meta name="author" content="ShanTianQi">





<title>Python机器学习入门 | ShanTianQi&#39;s Blog</title>



    <link rel="icon" href="../../../../favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="../../../../css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="../../../../js/script.js"></script>
    
    <script src="../../../../js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<!-- hexo injector head_end start --><script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@7.1.2/dist/mermaid.esm.min.mjs">
    mermaid.initialize(
      startOnLoad: true,
    );
    </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            pagebody.classList.add('dark-theme');
            // mobile
            document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            // if (isDark) {
            //     pagebody.classList.add('dark-theme');
            //     // mobile
            //     document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            // } else {
            //     pagebody.classList.remove('dark-theme');
            //     // mobile
            //     document.getElementById("mobile-toggle-theme").innerText = "· Light"
            // }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <!-- <div class="navbar-header header-logo"><a href="/">ShanTianQi&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="../../../../archives">Posts</a>
                
                    <a class="menu-item" href="../../../../category">Categories</a>
                
                    <a class="menu-item" href="../../../../tag">Tags</a>
                
                    <a class="menu-item" href="../../../../about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div> -->
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <!-- <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">ShanTianQi&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="../../../../archives">Posts</a>
                
                    <a class="menu-item" href="../../../../category">Categories</a>
                
                    <a class="menu-item" href="../../../../tag">Tags</a>
                
                    <a class="menu-item" href="../../../../about">About</a>
                
            </div>
        </div> -->
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Python机器学习入门</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">ShanTianQi</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">July 31, 2025&nbsp;&nbsp;16:54:29</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="../../../../categories/Python/">Python</a>
                            
                                <a href="../../../../categories/Python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="第一章-机器学习概述"><a href="#第一章-机器学习概述" class="headerlink" title="第一章 机器学习概述"></a>第一章 机器学习概述</h2><hr>
<p>机器学习是从<strong>数据</strong>中<strong>自动分析获得模型</strong>，并利用<strong>模型</strong>对未知数据进行预测</p>
<p>数据集的构成</p>
<ul>
<li>结构：特征值 + 目标值</li>
</ul>
<p>机器学习算法分类</p>
<ul>
<li><p>监督学习</p>
<ul>
<li>目标值是类别 —— 分类问题</li>
<li>目标值是连续型数据 —— 回归问题</li>
</ul>
</li>
<li><p>无监督学习</p>
<ul>
<li>没有目标值 —— 无监督学习</li>
</ul>
</li>
</ul>
<p>监督学习(supervised learning)(预测)</p>
<ul>
<li>定义：输入数据是由输入特征值和目标值所组成，函数的输出可以是一个连续的值(称为回归)，或是输出是有限个离散值(称作分类)</li>
<li><strong>分类k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归</strong> </li>
<li>回归 线性回归、岭回归</li>
</ul>
<p>无监督学习(unsupervised learning)</p>
<ul>
<li>定义：输入数据是由输入特征值所组成</li>
<li><strong>聚类 k-means</strong></li>
</ul>
<p>开发流程</p>
<ul>
<li>获取数据</li>
<li>数据处理</li>
<li>特征工程</li>
<li>机器学习算法训练 - 模型</li>
<li>模型评估</li>
<li>应用</li>
</ul>
<hr>
<h2 id="第二章-特征工程"><a href="#第二章-特征工程" class="headerlink" title="第二章 特征工程"></a>第二章 特征工程</h2><hr>
<h3 id="2-1-数据集"><a href="#2-1-数据集" class="headerlink" title="2.1 数据集"></a>2.1 数据集</h3><hr>
<p>可用数据集</p>
<ul>
<li>公司内部 百度</li>
<li>数据接口 付费</li>
<li>数据集：<ul>
<li>sklearn</li>
<li>kaggle</li>
<li>UCI</li>
</ul>
</li>
</ul>
<h4 id="2-1-1-Scikit-learn"><a href="#2-1-1-Scikit-learn" class="headerlink" title="2.1.1 Scikit-learn"></a>2.1.1 Scikit-learn</h4><ul>
<li>Python语言的机器学习工具</li>
<li>Scikit-learn包括许多知名的机器学习算法的实现</li>
<li>Scikit-learn文档完善，有丰富的API</li>
<li>1.7.1</li>
</ul>
<p><strong>sklearn.datasets</strong></p>
<ul>
<li>加载获取流行数据集</li>
<li>datasets.load_*()<ul>
<li>获取小规模数据集，数据包含在datasets里</li>
</ul>
</li>
<li>datasets.fetch_*(data_home &#x3D; None)<ul>
<li>获取大规模数据集，需要从网络上下载，函数的第一个参数是data_home，表示数据集下载的目录，默认是～&#x2F;scikit_learn_data&#x2F;</li>
</ul>
</li>
</ul>
<p><strong>sklearn小数据集</strong></p>
<ul>
<li>sklearn.datasets.load_iris()</li>
</ul>
<p>加载并返回鸢尾花数据集</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>数量</th>
</tr>
</thead>
<tbody><tr>
<td>类别</td>
<td>3</td>
</tr>
<tr>
<td>特征</td>
<td>4</td>
</tr>
<tr>
<td>样本数量</td>
<td>150</td>
</tr>
<tr>
<td>每个类别数量</td>
<td>50</td>
</tr>
</tbody></table>
<ul>
<li>sklearn.datasets.load_boston()</li>
</ul>
<p>加载并返回波士顿房价数据集</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>数量</th>
</tr>
</thead>
<tbody><tr>
<td>目标类别</td>
<td>5-50</td>
</tr>
<tr>
<td>特征</td>
<td>13</td>
</tr>
<tr>
<td>样本数量</td>
<td>506</td>
</tr>
</tbody></table>
<p><strong>sklearn大数据集</strong></p>
<ul>
<li>sklearn.datasets.fetch_20newgroups(data_home &#x3D; None, subset &#x3D; ‘train’)<ul>
<li>subset: ‘train’或者’test’, ‘all’，可选，选择要加载的数据集</li>
<li>训练集的”训练”，测试集的”测试”，两者的”全部”</li>
</ul>
</li>
</ul>
<p><strong>数据集返回值</strong></p>
<ul>
<li>load和fetch返回的数据类型datasets.base.Bunch(字典格式)<ul>
<li>data：特征数据数组，是[n_samples * n_features]的二维numpy.ndarray数组</li>
<li>target：标签数组，是n_samples的一维numpy.ndarray数组</li>
<li>DESCR：数据描述</li>
<li>feature_names：特征名，新闻数据，手写数字、回归数据集没有</li>
<li>target_names：标签名</li>
</ul>
</li>
</ul>
<p><strong>数据集的划分</strong></p>
<p>机器学习一般的数据集汇划分为两个部分：</p>
<ul>
<li>训练数据：用于训练，<strong>构建模型</strong></li>
<li>测试数据：在模型检验时使用，用于<strong>评估模型是否有效</strong></li>
</ul>
<p>划分比例：</p>
<ul>
<li>训练集：70% 80% 75%</li>
<li>测试集：30% 20% 25%</li>
</ul>
<p>数据集划分api</p>
<ul>
<li>sklearn.model_selection.train_test_split(arrays, *options)<ul>
<li>x 数据集的特征值</li>
<li>y 数据集的标签值</li>
<li>test_size测试集的大小，一般为float</li>
<li>random_state随机数种子，不同的种子会造成不同的随机采样结果，相同的种子采样结果相同</li>
<li>return训练集特征值，测试集特征值，训练集目标值，测试集目标值</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-2-特征工程介绍"><a href="#2-2-特征工程介绍" class="headerlink" title="2.2 特征工程介绍"></a>2.2 特征工程介绍</h3><hr>
<p>特征工程时使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程</p>
<ul>
<li>意义：会直接影响机器学习的效果</li>
</ul>
<p>特征工程位置与数据处理的比较</p>
<ul>
<li>pandas：一个数据读取非常方便以及基本的处理格式的工具</li>
<li>sklearn：对于特征的处理提供了强大的接口</li>
</ul>
<p>特征工程包含内容</p>
<ul>
<li>特征抽取</li>
<li>特征预处理</li>
<li>特征降维</li>
</ul>
<hr>
<h3 id="2-3-特征抽取"><a href="#2-3-特征抽取" class="headerlink" title="2.3 特征抽取"></a>2.3 特征抽取</h3><hr>
<p>将任意数据(如文本或图像)转换为可用于机器学习的数字特征</p>
<ul>
<li>字典特征提取(特征离散化)</li>
<li>文本特征提取</li>
<li>图像特征提取(深度学习介绍)</li>
</ul>
<p><strong>特征提取API</strong></p>
<ul>
<li>sklearn.feature_extraction</li>
</ul>
<h4 id="2-3-1-字典特征提取"><a href="#2-3-1-字典特征提取" class="headerlink" title="2.3.1 字典特征提取"></a>2.3.1 字典特征提取</h4><p><strong>作用：对字典数据进行特征值化</strong></p>
<ul>
<li>sklearn.feature_extraction.DictVectorizer(sparse &#x3D; Ture,…)<ul>
<li>DictVectorizer.fit_transform(X)     X：字典或者包含字典的迭代器 返回值：返回sparse(稀疏)矩阵</li>
<li>DictVectorizer.inverse_transform(X)     X：array数组或者sparse矩阵 返回值：转换之前数据格式</li>
<li>DictVectorizer.get_feature_names_out()    返回类别名称</li>
</ul>
</li>
</ul>
<p>稀疏矩阵：将非0值 按位置表示出来</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> sklearn
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
      <span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'上海'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">:</span> <span class="token number">60</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
      <span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>

<span class="token comment"># 实例化类DictVectorizer</span>
transfer <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 调用fit_transform方法输入数据并转换</span>
data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>data_new<span class="token punctuation">)</span> <span class="token comment"># 没有加上sparse = False参数的结果</span>
<span class="token comment"># &lt;Compressed Sparse Row sparse matrix of dtype 'float64'</span>
<span class="token comment"># 	with 6 stored elements and shape (3, 4)></span>
<span class="token comment">#   Coords	Values</span>
<span class="token comment">#   (0, 1)	1.0</span>
<span class="token comment">#   (0, 3)	100.0</span>
<span class="token comment">#   (1, 0)	1.0</span>
<span class="token comment">#   (1, 3)	60.0</span>
<span class="token comment">#   (2, 2)	1.0</span>
<span class="token comment">#   (2, 3)	30.0</span>

transfer <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
<span class="token comment"># [[  0.   1.   0. 100.]</span>
<span class="token comment">#  [  1.   0.   0.  60.]</span>
<span class="token comment">#  [  0.   0.   1.  30.]]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>transfer<span class="token punctuation">.</span>get_feature_names_out<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># ['city=上海' 'city=北京' 'city=深圳' 'temperature']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>对于特征当中存在的类别信息，都会做one-hot编码处理</p>
<h4 id="2-3-2-文本特征提取"><a href="#2-3-2-文本特征提取" class="headerlink" title="2.3.2 文本特征提取"></a>2.3.2 文本特征提取</h4><p><strong>作用：对文本数据进行特征值化</strong></p>
<ul>
<li>sklearn.feature_extraction.text.CountVectorizer(stop_words &#x3D; [])   stop_words 停用词<ul>
<li>返回词频矩阵</li>
</ul>
</li>
<li>CountVectorizer.fit_transform(X)   X：文本或者包含文本字符串的可迭代对象 返回值：返回sparse矩阵</li>
<li>CountVectorizer.inverse_transform(X)   X：array数组或者sparse矩阵 返回值：转换之前数据格式</li>
<li>CountVectorizer.get_feature_names_out()   返回值：单词列表</li>
<li>sklearn.feature_extranction.text.TfidfVectorizer</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"life is short, i like python"</span><span class="token punctuation">,</span>
        <span class="token string">"life is too long, i dislike python"</span><span class="token punctuation">]</span>

transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 统计每个样本特征词出现的个数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>transfer<span class="token punctuation">.</span>get_feature_names_out<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># [[0 1 1 1 0 1 1 0]</span>
<span class="token comment">#  [1 1 1 0 1 1 0 1]]</span>
<span class="token comment"># ['dislike' 'is' 'life' 'like' 'long' 'python' 'short' 'too']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>中文分词，jieba</p>
<p>jieba.cut()</p>
<ul>
<li>返回词语组成的生成器</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> idlelib<span class="token punctuation">.</span>pyparse <span class="token keyword">import</span> trans

<span class="token keyword">import</span> jieba
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"活着的意义，不是为了死去，而是为了活着本身。"</span><span class="token punctuation">,</span>
        <span class="token string">"活着本身就有一种力量，这种力量支撑着我们度过苦难，也让我们在苦难中依然能够感受到生活的温暖。"</span><span class="token punctuation">]</span>

data_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> text <span class="token keyword">in</span> data<span class="token punctuation">:</span>
    data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

transformer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
X_transformed <span class="token operator">=</span> transformer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X_transformed<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>transformer<span class="token punctuation">.</span>get_feature_names_out<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># [[0 1 2 0 0 0 1 0 0 0 1 1 2 0 0 1 0 0 0]</span>
<span class="token comment">#  [1 0 0 1 2 1 0 1 2 1 1 0 1 1 1 0 1 2 1]]</span>
<span class="token comment"># ['一种' '不是' '为了' '依然' '力量' '度过' '意义' '感受' '我们' '支撑' '本身' '死去' '活着' '温暖'</span>
<span class="token comment">#  '生活' '而是' '能够' '苦难' '这种']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h4 id="2-3-3-Tf-idf文本特征提取"><a href="#2-3-3-Tf-idf文本特征提取" class="headerlink" title="2.3.3 Tf-idf文本特征提取"></a>2.3.3 Tf-idf文本特征提取</h4><ul>
<li>TF-IDF的主要思想是：如果<strong>某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现</strong>，则认为此词或者短语具有很好的类别区分能力，适合用来分类。</li>
<li><strong>TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度</strong></li>
</ul>
<p><strong>公式</strong></p>
<ul>
<li>词频(term frequency，tf)指的是某一个给定的词语在该文件中出现的频率</li>
<li>逆向文档频率(inverse document frequency，idf)是一个词语普遍重要性的度量，某一特定词语的idf，可以<strong>由总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到</strong></li>
</ul>
<p><strong>API</strong></p>
<ul>
<li><p>sklearn.feature_extraction.text.TfidfVectorizer(stop_words &#x3D; None,…)</p>
</li>
<li><p>返回词的权重矩阵</p>
<ul>
<li><p>TfidfVectorizer.fit_transform(X)</p>
<ul>
<li><p>X：文本或者包含文本字符串的可迭代对象</p>
</li>
<li><p>返回值：返回sparse矩阵</p>
</li>
</ul>
</li>
<li><p>TfidfVectorizer.inverse_transform(X)</p>
<ul>
<li>X：array数组或者sparse矩阵</li>
<li>返回值：转换之前数据格式</li>
</ul>
</li>
<li><p>TfidfVectorizer.get_feature_names_out()</p>
<ul>
<li>返回值：单词列表</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> idlelib<span class="token punctuation">.</span>pyparse <span class="token keyword">import</span> trans

<span class="token keyword">import</span> jieba
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer<span class="token punctuation">,</span> TfidfVectorizer

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"活着的意义，不是为了死去，而是为了活着本身。"</span><span class="token punctuation">,</span>
        <span class="token string">"活着本身就有一种力量，这种力量支撑着我们度过苦难，也让我们在苦难中依然能够感受到生活的温暖。"</span><span class="token punctuation">]</span>

data_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> text <span class="token keyword">in</span> data<span class="token punctuation">:</span>
    data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

transformer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
X_transformed <span class="token operator">=</span> transformer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X_transformed<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>transformer<span class="token punctuation">.</span>get_feature_names_out<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Building prefix dict from the default dictionary ...</span>
<span class="token comment"># Loading model from cache /var/folders/vv/y2k4cvj91fjbmw1cp4415wtr0000gn/T/jieba.cache</span>
<span class="token comment"># [[0.         0.30814893 0.61629785 0.         0.         0.</span>
<span class="token comment">#   0.30814893 0.         0.         0.         0.2192505  0.30814893</span>
<span class="token comment">#   0.438501   0.         0.         0.30814893 0.         0.</span>
<span class="token comment">#   0.        ]</span>
<span class="token comment">#  [0.21314023 0.         0.         0.21314023 0.42628046 0.21314023</span>
<span class="token comment">#   0.         0.21314023 0.42628046 0.21314023 0.15165103 0.</span>
<span class="token comment">#   0.15165103 0.21314023 0.21314023 0.         0.21314023 0.42628046</span>
<span class="token comment">#   0.21314023]]</span>
<span class="token comment"># ['一种' '不是' '为了' '依然' '力量' '度过' '意义' '感受' '我们' '支撑' '本身' '死去' '活着' '温暖'</span>
<span class="token comment">#  '生活' '而是' '能够' '苦难' '这种']</span>
<span class="token comment"># Loading model cost 0.264 seconds.</span>
<span class="token comment"># Prefix dict has been built successfully.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="2-4-特征预处理"><a href="#2-4-特征预处理" class="headerlink" title="2.4 特征预处理"></a>2.4 特征预处理</h3><hr>
<p>通过<strong>一些转换函数</strong>将特征数据<strong>转换成更加适合算法模型</strong>的特征数据过程</p>
<p>数值型数据的无量纲化</p>
<ul>
<li>归一化</li>
<li>标准化</li>
</ul>
<p><strong>特征预处理API</strong></p>
<ul>
<li>sklearn.preprocessing</li>
</ul>
<p>特征的<strong>单位或者大小相差较大、或者某些特征的方差相比其他的特征要大出几个数量级，容易影响(支配)目标结果</strong>，使得一些算法无法学习到其它的特征</p>
<h4 id="2-4-1-归一化"><a href="#2-4-1-归一化" class="headerlink" title="2.4.1 归一化"></a>2.4.1 归一化</h4><p>通过对原始数据进行变换把数据映射到(默认为[0, 1])之间</p>
<p>公式<br>$$<br>X’ &#x3D; \frac{x - min}{\max-min}<br>$$</p>
<p>$$<br>X’’ &#x3D; X’ * (mx - mi) + mi<br>$$</p>
<p>作用于每一列，max为一列的最大值，min为一列的最小值，那么X’’为最终结果，mx、mi分别为指定区间值，默认mx为1，mi为0</p>
<img src="https://tonkyshan.cn/img/20250805102611.png" style="zoom:50%;" />





<p><strong>API</strong></p>
<ul>
<li>sklearn.preprocessing.MinMaxScaler(feature_range &#x3D; (0, 1)…)<ul>
<li>MinMaxScalar.fit_transform(X)<ul>
<li>X：numpy array格式的数据[n_samples, n_features]</li>
</ul>
</li>
<li>返回值：转换后的形状相同的array</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">transfer <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>



<p>缺点：最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性(稳定性)较差，只适合传统精确小数据场景</p>
<h4 id="2-4-2-标准化"><a href="#2-4-2-标准化" class="headerlink" title="2.4.2 标准化"></a>2.4.2 标准化</h4><p>通过对原始数据进行变换把数据变换到均值为0，标准差为1范围内<br>$$<br>X’ &#x3D; \frac{x - mean}{σ}<br>$$<br>作用于每一列，mean为平均值，σ为标准差</p>
<ul>
<li>对于归一化来说：如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变</li>
<li>对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小</li>
</ul>
<p><strong>API</strong></p>
<ul>
<li>sklearn.preprocessing.StandardScaler()<ul>
<li>处理之后，对每列来说，所有数据都聚集在均值为0附近，标准差为1</li>
<li>StandardScaler.fit_transform(X)<ul>
<li>X：numpy array格式的数据[n_samples, n_features]</li>
</ul>
</li>
<li>返回值：转换后的形状相同的array</li>
</ul>
</li>
</ul>
<p>在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景</p>
<hr>
<h3 id="2-5-特征降维"><a href="#2-5-特征降维" class="headerlink" title="2.5 特征降维"></a>2.5 特征降维</h3><hr>
<p>降维是指在某些限定条件下，降低随机变量(特征)个数，得到一组”不相关”主变量的过程</p>
<ul>
<li>降低随机变量的个数</li>
<li>相关特征(correlated feature)<ul>
<li>相对湿度与降雨量之间的相关</li>
<li>等的</li>
</ul>
</li>
</ul>
<p>正是因为在进行训练的时候，我们都是使用特征进行学习，如果特征本身存在问题或者特征之间相关性较强，对于算法学习预测会影响较大</p>
<p><strong>两种降维方式</strong></p>
<ul>
<li>特征选择</li>
<li>主成分分析(一种特征提取的方式)</li>
</ul>
<h4 id="2-5-1-特征选择"><a href="#2-5-1-特征选择" class="headerlink" title="2.5.1 特征选择"></a>2.5.1 特征选择</h4><p>数据中包含<strong>冗余或相关变量(或称特征、属性、指标等)<strong>，旨在从</strong>原有特征中找出主要特征</strong></p>
<p><strong>方法</strong></p>
<ul>
<li>Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联<ul>
<li>方差选择法：低方差特征过滤</li>
<li>相关系数</li>
</ul>
</li>
<li>Embedded(嵌入式)：算法自动选择特征(特征与目标值之间的关联)<ul>
<li>决策树：信息熵、信息增益</li>
<li>正则化：L1、L2</li>
<li>深度学习：卷积等</li>
</ul>
</li>
</ul>
<p><strong>模块</strong></p>
<ul>
<li>sklearn.feature_selection</li>
</ul>
<p><strong>过滤式</strong></p>
<p><strong>一、低方差特征过滤</strong></p>
<p>删除低方差的一些特征</p>
<ul>
<li>特征方差小：某个特征大多样本的值比较相近</li>
<li>特征方差大：某个特征很多样本的值都有差别</li>
</ul>
<p><strong>API</strong></p>
<ul>
<li>sklearn.feature_selection.VarianceThreshold(threshold &#x3D; 0.0)<ul>
<li>删除所有低方差特征</li>
<li>Variance.fit_transform(X)<ul>
<li>X：numpy array格式的数据[n_samples, n_features]</li>
<li>返回值：训练集差异低于threshold的特征将被删除，默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">transfer <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>



<p><strong>二、相关系数</strong><br>$$<br>r&#x3D;\frac{n \sum x y-\sum x \sum y}{\sqrt{n \sum x^{2}-\left(\sum x\right)^{2}} \sqrt{n \sum y^{2}-\left(\sum y\right)^{2}}}<br>$$<br>特点</p>
<p>相关系数的值介于-1与+1之间，即-1 &lt;&#x3D; r &lt;&#x3D; 1，其性质如下：</p>
<ul>
<li><strong>当 r &gt; 1时，表示两变量正相关，r &lt; 0时，两变量为负相关</strong></li>
<li>当 |r| &#x3D; 1时，表示两变量为完全相关，当r &#x3D; 0时，表示两变量间无相关关系</li>
<li><strong>当 0 &lt; |r| &lt; 1 时，表示两变量存在一定程度的相关。且|r|越接近1，两变量间线性关系越密切；|r|越接近于0，表示两变量的线性相关越弱</strong></li>
<li><strong>一般可按三级划分：|r| &lt; 0.4为低度相关；0.4 &lt;&#x3D; |r| &lt; 0.7为显著性相关；0.7 &lt;&#x3D; |r| &lt; 1为高度线性相关</strong></li>
</ul>
<p><strong>API</strong></p>
<ul>
<li>from scipy.stats import pearsonr<ul>
<li>x：(N,) array_like</li>
<li>y：(N,) array_like   Returns：(Pearson’s correlation coeffcient，p-value)</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-6-主成分分析-PCA"><a href="#2-6-主成分分析-PCA" class="headerlink" title="2.6 主成分分析(PCA)"></a>2.6 主成分分析(PCA)</h3><hr>
<p>高维度数据转化为低纬度数据的过程，在此过程中可能会舍弃原有数据、创造新的变量</p>
<p>作用：时数据维数压缩，尽可能降低原数据的维数(复杂度)，损失少量信息</p>
<p>应用：回归分析或者聚类分析当中</p>
<p><strong>API</strong></p>
<ul>
<li>sklearn.decomposition.PCA(n_components &#x3D; None)<ul>
<li>将数据分解为较低维数空间</li>
<li>n_components：<ul>
<li>小数：表示保留百分之多少的信息</li>
<li>整数：减少到多少特征</li>
</ul>
</li>
<li>PCA.fit_transform(X) X：numpy array格式的数据 [n_samples, n_features]</li>
<li>返回值：转换后指定维度的array</li>
</ul>
</li>
</ul>
<hr>
<h2 id="第三章-分类算法"><a href="#第三章-分类算法" class="headerlink" title="第三章 分类算法"></a>第三章 分类算法</h2><hr>
<h3 id="3-1-sklearn转换器和估计器"><a href="#3-1-sklearn转换器和估计器" class="headerlink" title="3.1 sklearn转换器和估计器"></a>3.1 sklearn转换器和估计器</h3><hr>
<p><strong>转换器</strong>——特征工程的父类</p>
<p>特征工程的接口称之为转换器，其中转换器调用有这么几种形式</p>
<ul>
<li>fit_transform</li>
<li>fit</li>
<li>transform</li>
</ul>
<p>1、实例化(实例化的是一个转换器类(Transformer))</p>
<p>2、调用fit_transform(对于文档建立分类词频矩阵，不能同时调用)</p>
<p>标准化：</p>
<p>(x - mean) &#x2F; std</p>
<p>fit_transform()</p>
<ul>
<li>fit()    计算 每一列的平均值、标准差</li>
<li>transform()   (x - mean) &#x2F; std进行最终的转换</li>
</ul>
<p><strong>估计器</strong>——sklearn机器学习算法的实现</p>
<p>在sklearn中，估计器(estimator)是一个重要的角色，是一类实现了算法的API</p>
<p>1、用于分类的估计器：</p>
<ul>
<li>sklearn.neighbors k-近邻算法</li>
<li>sklearn.naive_bayes 贝叶斯</li>
<li>sklearn.linear_model.LogisticRegression 逻辑回归</li>
<li>sklearn.tree 决策树与随机森林</li>
</ul>
<p>2、用于回归的估计器</p>
<ul>
<li>sklearn.linear_model.LinearRegression 线性回归</li>
<li>sklearn.linear_model.Ridge 岭回归</li>
</ul>
<p>3、用于无监督学习的估计器</p>
<ul>
<li>sklearn.cluster.KMeans 聚类</li>
</ul>
<p>1、实例化一个estimator</p>
<p>2、estimator.fit(x_train, y_train)计算——调用完毕，模型生成</p>
<p>3、模型评估</p>
<ul>
<li>直接比对真实值和预测值<ul>
<li>y_predict &#x3D; estimator.predict(x_test)</li>
<li>y_test &#x3D;&#x3D; y_predict</li>
</ul>
</li>
<li>计算准确率<ul>
<li>accuracy &#x3D; estimator.score(x_test, y_test)</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-2-K-近邻算法"><a href="#3-2-K-近邻算法" class="headerlink" title="3.2 K-近邻算法"></a>3.2 K-近邻算法</h3><hr>
<p>如果一个样本在特征空间中的<strong>k个最相似(即特征空间中最临近)的样本中的大多数属于某一个类别</strong>，则该样本也属于这个类别</p>
<blockquote>
<p>来源：KNN算法最早是由Cover和Hart提出的一种分类算法</p>
</blockquote>
<p><strong>距离公式</strong></p>
<p>两个样本的距离可以通过如下公式计算，又称欧式距离<br>$$<br>比如说，a(a1, a2, a3), b(b1, b2, b3)\ \sqrt{(a 1-b 1)^{2}+(a 2-b 2)^{2}+(a 3-b 3)^{2}}<br>$$</p>
<p><strong>API</strong></p>
<ul>
<li>sklearn.neighborsClassifier(n_neighbors &#x3D; 5, algorithm &#x3D; ‘auto’)<ul>
<li>n_neighbors：int 可选(默认 &#x3D; 5) k_neighbors查询默认使用的邻居数</li>
<li>algorithm：{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}，可选用于计算最近邻居的算法(不同实现方式影响效率)<ul>
<li>‘ball_tree’将会使用BallTree</li>
<li>‘kd_tree’将使用KDTree</li>
<li>‘auto’将尝试根据传递给fit方法的值来决定最合适的算法</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>案例 预测鸢尾花</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler


<span class="token keyword">def</span> <span class="token function">knn_iris</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    使用KNN 算法对鸢尾花进行分类
    :return:
    """</span>
    <span class="token comment"># 1、获取数据</span>
    iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 2、划分数据集</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">)</span>

    <span class="token comment"># 3、特征工程：标准化</span>
    transfer <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x_train <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
    x_test <span class="token operator">=</span> transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

    <span class="token comment"># 4、KNN算法预估器</span>
    estimator <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
    estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

    <span class="token comment"># 5、模型评估</span>
    y_predict <span class="token operator">=</span> estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:"</span> <span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"对比真实值和预测值："</span><span class="token punctuation">,</span> y_test <span class="token operator">==</span> y_predict<span class="token punctuation">)</span>

    score <span class="token operator">=</span> estimator<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"准确率："</span><span class="token punctuation">,</span> score<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    knn_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
<span class="token comment"># y_predict: [0 2 0 0 2 1 1 0 2 1 2 1 2 2 1 1 2 1 1 0 0 2 0 0 1 1 1 2 0 1 0 1 0 0 1 2 1 2]</span>
<span class="token comment"># 对比真实值和预测值： [ True  True  True  True  True  True False  True  True  True  True  True</span>
<span class="token comment">#   True  True  True False  True  True  True  True  True  True  True  True</span>
<span class="token comment">#   True  True  True  True  True  True  True  True  True  True False  True</span>
<span class="token comment">#   True  True]</span>
<span class="token comment"># 准确率： 0.9210526315789473</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>优点</p>
<ul>
<li>简单，易于理解，易于实现，无需训练</li>
</ul>
<p>缺点</p>
<ul>
<li>懒惰算法，对测试样本分类时的计算量大，内存开销大</li>
<li>必须指定k值，k值选择不当则分类精度不能保证</li>
</ul>
<p>使用场景</p>
<ul>
<li>小数据场景，几千～几万样本，具体场景具体业务去测试</li>
</ul>
<hr>
<h3 id="3-3-模型选择与调优"><a href="#3-3-模型选择与调优" class="headerlink" title="3.3 模型选择与调优"></a>3.3 模型选择与调优</h3><hr>
<h4 id="3-3-1-交叉验证"><a href="#3-3-1-交叉验证" class="headerlink" title="3.3.1 交叉验证"></a>3.3.1 交叉验证</h4><p>交叉验证：将拿到的训练数据，分为训练和验证集，如 将数据分成4份，其中一份作为验证集，然后经过4次(组)的测试，每次都更换不同的验证集，即得到4组模型的结果，取平均值作为最终结果，又称4折交叉验证</p>
<h4 id="3-3-2-超参数搜索——网格搜索-Grid-Search"><a href="#3-3-2-超参数搜索——网格搜索-Grid-Search" class="headerlink" title="3.3.2 超参数搜索——网格搜索(Grid Search)"></a>3.3.2 超参数搜索——网格搜索(Grid Search)</h4><p>通常情况下，<strong>有很多参数是需要手动指定的(如k-近邻算法中的k值)，这种叫超参数</strong>，但是手动过程繁杂，所以需要对模型预设几种超参数组合<strong>，每组超参数都采用交叉验证来进行评估，最后选出最优参数组合建立模型</strong></p>
<p><strong>模型选择与调优API</strong></p>
<ul>
<li>sklearn.model_selection.GridSearchCV(estimator, param_grid &#x3D; None, cv &#x3D; None)<ul>
<li>对估计器的指定参数值进行详尽搜索</li>
<li>estimator：估计器对象</li>
<li>param_grid：估计器参数(dict){“n_neighbors”: [1, 3, 5]}</li>
<li>cv：指定几折交叉验证</li>
<li>fit()：输入训练数据</li>
<li>score()：准确率</li>
<li>结果分析：<ul>
<li>最佳参数：best_params_</li>
<li>最佳结果：best_score_</li>
<li>最佳估计器：best_estimator_</li>
<li>交叉验证结果：cv_results_</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>鸢尾花</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">knn_iris_gscv</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    使用KNN 算法对鸢尾花进行分类, 添加网格搜索和交叉验证
    :return:
    """</span>
    <span class="token comment"># 1、获取数据</span>
    iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 2、划分数据集</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">)</span>

    <span class="token comment"># 3、特征工程：标准化</span>
    transfer <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x_train <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
    x_test <span class="token operator">=</span> transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

    <span class="token comment"># 4、KNN算法预估器</span>
    estimator <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
    estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

    <span class="token comment"># 加入网格搜索和交叉验证</span>
    estimator <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span> param_grid <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>
    estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

    <span class="token comment"># 5、模型评估</span>
    y_predict <span class="token operator">=</span> estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:"</span> <span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"对比真实值和预测值："</span><span class="token punctuation">,</span> y_test <span class="token operator">==</span> y_predict<span class="token punctuation">)</span>

    score <span class="token operator">=</span> estimator<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"准确率："</span><span class="token punctuation">,</span> score<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳参数"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳结果"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳估计器"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"交叉验证结果"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>
  
<span class="token comment"># y_predict: [0 2 0 0 2 1 2 0 2 1 2 1 2 2 1 1 2 1 1 0 0 2 0 0 1 1 1 2 0 1 0 1 0 0 1 2 1</span>
<span class="token comment">#  2]</span>
<span class="token comment"># 对比真实值和预测值： [ True  True  True  True  True  True  True  True  True  True  True  True</span>
<span class="token comment">#   True  True  True False  True  True  True  True  True  True  True  True</span>
<span class="token comment">#   True  True  True  True  True  True  True  True  True  True False  True</span>
<span class="token comment">#   True  True]</span>
<span class="token comment"># 准确率： 0.9473684210526315</span>
<span class="token comment"># 最佳参数 &#123;'n_neighbors': 11&#125;</span>
<span class="token comment"># 最佳结果 0.9734848484848484</span>
<span class="token comment"># 最佳估计器 KNeighborsClassifier(n_neighbors=11)</span>
<span class="token comment"># 交叉验证结果 &#123;'mean_fit_time': array([0.00012665, 0.0001209 , 0.00011959, 0.00011954, 0.00012078,</span>
<span class="token comment">#        0.0001174 ]), 'std_fit_time': array([1.49413711e-05, 1.09113690e-05, 5.32714825e-06, 4.85601935e-06,</span>
<span class="token comment">#        5.19424300e-06, 2.41309756e-06]), 'mean_score_time': array([0.00033486, 0.00030804, 0.00029821, 0.00030265, 0.00033834,</span>
<span class="token comment">#        0.00031242]), 'std_score_time': array([8.85420127e-05, 3.18315144e-05, 1.89715283e-05, 7.72137627e-06,</span>
<span class="token comment">#        1.12072276e-04, 7.35798518e-06]), 'param_n_neighbors': masked_array(data=[1, 3, 5, 7, 9, 11],</span>
<span class="token comment">#              mask=[False, False, False, False, False, False],</span>
<span class="token comment">#        fill_value=999999), 'params': [&#123;'n_neighbors': 1&#125;, &#123;'n_neighbors': 3&#125;, &#123;'n_neighbors': 5&#125;, &#123;'n_neighbors': 7&#125;, &#123;'n_neighbors': 9&#125;, &#123;'n_neighbors': 11&#125;], 'split0_test_score': array([1., 1., 1., 1., 1., 1.]), 'split1_test_score': array([0.91666667, 0.91666667, 1.        , 0.91666667, 0.91666667,</span>
<span class="token comment">#        0.91666667]), 'split2_test_score': array([1., 1., 1., 1., 1., 1.]), 'split3_test_score': array([1.        , 1.        , 1.        , 1.        , 0.90909091,</span>
<span class="token comment">#        1.        ]), 'split4_test_score': array([1., 1., 1., 1., 1., 1.]), 'split5_test_score': array([0.90909091, 0.90909091, 1.        , 1.        , 1.        ,</span>
<span class="token comment">#        1.        ]), 'split6_test_score': array([1., 1., 1., 1., 1., 1.]), 'split7_test_score': array([0.90909091, 0.90909091, 0.90909091, 0.90909091, 1.        ,</span>
<span class="token comment">#        1.        ]), 'split8_test_score': array([1., 1., 1., 1., 1., 1.]), 'split9_test_score': array([0.90909091, 0.81818182, 0.81818182, 0.81818182, 0.81818182,</span>
<span class="token comment">#        0.81818182]), 'mean_test_score': array([0.96439394, 0.95530303, 0.97272727, 0.96439394, 0.96439394,</span>
<span class="token comment">#        0.97348485]), 'std_test_score': array([0.04365767, 0.0604591 , 0.05821022, 0.05965639, 0.05965639,</span>
<span class="token comment">#        0.05742104]), 'rank_test_score': array([5, 6, 2, 3, 3, 1], dtype=int32)&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="3-4-朴素贝叶斯算法"><a href="#3-4-朴素贝叶斯算法" class="headerlink" title="3.4 朴素贝叶斯算法"></a>3.4 朴素贝叶斯算法</h3><hr>
<h4 id="3-4-1-概率基础"><a href="#3-4-1-概率基础" class="headerlink" title="3.4.1 概率基础"></a>3.4.1 概率基础</h4><ul>
<li>概率定义为一件事情发生的可能性</li>
</ul>
<p>扔出一个硬币，结果头像朝上</p>
<p>P(X)：取值在[0, 1]</p>
<p>朴素：特征与特征之间是相互独立的</p>
<h4 id="3-4-2-联合概率、条件概率与相互独立"><a href="#3-4-2-联合概率、条件概率与相互独立" class="headerlink" title="3.4.2 联合概率、条件概率与相互独立"></a>3.4.2 联合概率、条件概率与相互独立</h4><ul>
<li>联合概率：包含多个条件、且所有条件同时成立的概率<ul>
<li>记作：P(A, B)</li>
</ul>
</li>
<li>条件概率：就是事件A在另外一个事件B已经发生条件下的发生概率<ul>
<li>记作：P(A | B)</li>
</ul>
</li>
<li>相互独立：如果P(A, B) &#x3D; P(A)P(B)，则称事件A与事件B相互独立</li>
</ul>
<h4 id="3-4-3-贝叶斯公式"><a href="#3-4-3-贝叶斯公式" class="headerlink" title="3.4.3 贝叶斯公式"></a>3.4.3 贝叶斯公式</h4><p>$$<br>P(C|W) &#x3D; \frac{P(W|C)P(C)}{P(W)}<br>$$</p>
<p>W为给定文档的特征值(频数统计，预测文档提供)，c为文档类别</p>
<p>应用场景：文本分类 (单词作为特征)</p>
<p>那么这个公式如果应用在分章分类的场景中，我们可以这样看：<br>$$<br>P(C|F1,F2,…) &#x3D; \frac{P(F1,F2,…|C)P(C)}{P(F1,F2,…)}<br>$$<br>其中c可以是不同类别</p>
<p>公式分为三个部分：</p>
<ul>
<li>P(C)：每个文档类别的概率(某文档类别数&#x2F;总文档数量)</li>
<li>P(W|C)：给定类型下特征(被预测文档中出现的词)的概率<ul>
<li>计算方法：P(F1 | C) &#x3D; Ni&#x2F;N(训练文档中去计算)<ul>
<li>Ni为该F1词在C类别所有文档中出现的次数</li>
<li>N为所属类别C下的文档所有词出现的次数和</li>
</ul>
</li>
</ul>
</li>
<li>P(F1,F2,…)预测文档中每个词的概率</li>
</ul>
<h4 id="3-4-4-拉普拉斯平滑系数"><a href="#3-4-4-拉普拉斯平滑系数" class="headerlink" title="3.4.4 拉普拉斯平滑系数"></a>3.4.4 拉普拉斯平滑系数</h4><p>目的：防止计算出的分类概率为0<br>$$<br>P(F1|C) &#x3D; \frac{Ni + α}{N + αm}<br>$$</p>
<h4 id="3-4-5-API"><a href="#3-4-5-API" class="headerlink" title="3.4.5 API"></a>3.4.5 API</h4><ul>
<li>sklearn.naive_bayes.MultinomialNB(alpha &#x3D; 1.0)<ul>
<li>朴素贝叶斯分类</li>
<li>alpha：拉普拉斯平滑系数</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">nb_news</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    用朴素贝叶斯算法对新闻进行分类
    :return: 
    '''</span>
    <span class="token comment"># 1、获取数据</span>
    news <span class="token operator">=</span> fetch_20newsgroups<span class="token punctuation">(</span>subset <span class="token operator">=</span> <span class="token string">'all'</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 2、划分数据集</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>news<span class="token punctuation">.</span>data<span class="token punctuation">,</span> news<span class="token punctuation">.</span>target<span class="token punctuation">)</span>
    
    <span class="token comment"># 3、特征工程：文本特征抽取-tfidf</span>
    transfer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x_train <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
    x_test <span class="token operator">=</span> transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    
    <span class="token comment"># 4、朴素贝叶斯算法预估器流程</span>
    estimator <span class="token operator">=</span> MultinomialNB<span class="token punctuation">(</span><span class="token punctuation">)</span>
    estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
    
    <span class="token comment"># 5、模型评估</span>
    <span class="token comment"># 方法一：直接比对真实值和预测值</span>
    y_predict <span class="token operator">=</span> estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:"</span> <span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值："</span><span class="token punctuation">,</span> y_test <span class="token operator">==</span> y_predict<span class="token punctuation">)</span>
    
    <span class="token comment"># 方法二：计算准确率</span>
    score <span class="token operator">=</span> estimator<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"准确率为："</span><span class="token punctuation">,</span> score<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> <span class="token boolean">None</span>
  
<span class="token comment"># y_predict: [ 4  9  4 ... 16  9 12]</span>
<span class="token comment"># 直接比对真实值和预测值： [ True  True  True ...  True  True  True]</span>
<span class="token comment"># 准确率为： 0.8406196943972836</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>优点：</p>
<ul>
<li>朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率</li>
<li>对缺失数据不太敏感，算法也比较简单，常用于文本分类</li>
<li>分类准确度高，速度快</li>
</ul>
<p>缺点：</p>
<ul>
<li>由于使用了样本属性独立性的假设，所以如果特征属性有关联时其效果不好</li>
</ul>
<hr>
<h3 id="3-5-决策树"><a href="#3-5-决策树" class="headerlink" title="3.5 决策树"></a>3.5 决策树</h3><hr>
<p><strong>一、原理</strong></p>
<ul>
<li>信息熵、信息增益等</li>
</ul>
<p><strong>二、信息熵的定义</strong></p>
<ul>
<li>H的专业术语称之为信息熵，单位为比特</li>
</ul>
<p>$$<br>H(X)&#x3D;-\sum_{i&#x3D;1}^{n}P\left(x_{i}\right)\log_{b}P\left(x_{i}\right)<br>$$</p>
<p><strong>三、决策树划分依据之一   信息增益</strong></p>
<p>特征A对训练数据集D的信息增益g(D, A)定义为集合D的信息熵H(D)与特征A给定条件下D的信息条件熵H(D|A)之差，即公式为：<br>$$<br>g(D,A) &#x3D; H(D) - H(D|A)<br>$$</p>
<p>信息熵计算<br>$$<br>H(D)&#x3D;-\sum_{k&#x3D;1}^{k}\frac{|C_{k}|}{|D|}log\frac{|C_{k}|}{|D|}<br>$$<br>条件熵的计算<br>$$<br>H(D|A)&#x3D;\sum_{i&#x3D;1}^{n}\frac{|D_{i}|}{|D|}H(D_{i}) &#x3D; -\sum_{i&#x3D;1}^{n}\frac{|D_{i}|}{|D|}\sum_{k&#x3D;1}^{k}\frac{|D_{ik}|}{|Di|}log\frac{|D_{ik}|}{|Di|}<br>$$<br>Ck表示属于某个类别的样本数</p>
<blockquote>
<p>tips：信息增益表示得知特征X的信息而息的不确定性减少的程度使得类Y的信息熵减少的程度</p>
</blockquote>
<ul>
<li>ID3<ul>
<li>信息增益 最大的准则</li>
</ul>
</li>
<li>C4.5<ul>
<li>信息增益比 最大的准则</li>
</ul>
</li>
<li>CART<ul>
<li>分类树：基尼系数 最小的准则 在sklearn中可以选择划分的默认原则</li>
<li>优势：划分更加细腻</li>
</ul>
</li>
</ul>
<h4 id="3-5-1-决策树API"><a href="#3-5-1-决策树API" class="headerlink" title="3.5.1 决策树API"></a>3.5.1 决策树API</h4><ul>
<li>class sklearn.tree.DecisionTreeClassifier(criterion &#x3D; ‘gini’, max_depth &#x3D; None, random_state &#x3D; None)<ul>
<li>决策树分类器</li>
<li>criterion：默认时’gini’系数，也可以选择信息增益的熵’entropy’</li>
<li>max_depth：树的深度大小</li>
<li>random_state：随机数种子</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">decision_iris</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    用决策树对鸢尾花进行分类
    :return:
    '''</span>
    <span class="token comment"># 1、获取数据集</span>
    iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 2、划分数据集</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">)</span>

    <span class="token comment"># 3、决策树预估器</span>
    estimator <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>criterion <span class="token operator">=</span> <span class="token string">"entropy"</span><span class="token punctuation">)</span>
    estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

    <span class="token comment"># 4、模型评估</span>
    <span class="token comment"># 方法一：直接比对真实值和预测值</span>
    y_predict <span class="token operator">=</span> estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:"</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值："</span><span class="token punctuation">,</span> y_test <span class="token operator">==</span> y_predict<span class="token punctuation">)</span>

    <span class="token comment"># 方法二：计算准确率</span>
    score <span class="token operator">=</span> estimator<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"准确率为："</span><span class="token punctuation">,</span> score<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>
  
<span class="token comment"># y_predict: [0 2 0 0 2 1 2 0 2 1 2 1 2 2 1 1 2 1 1 0 0 2 0 0 1 1 1 2 0 1 0 1 0 0 1 2 1 2]</span>
<span class="token comment"># 直接比对真实值和预测值： [ True  True  True  True  True  True  True  True  True  True  True  True</span>
<span class="token comment">#   True  True  True False  True  True  True  True  True  True  True  True</span>
<span class="token comment">#   True  True  True  True  True  True  True  True  True  True False  True</span>
<span class="token comment">#   True  True]</span>
<span class="token comment"># 准确率为： 0.9473684210526315</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h4 id="3-5-2-决策树可视化"><a href="#3-5-2-决策树可视化" class="headerlink" title="3.5.2 决策树可视化"></a>3.5.2 决策树可视化</h4><p>1、保存树的结构到dot文件</p>
<ul>
<li>sklearn.tree.export_graphviz()该函数能够导出DOT格式<ul>
<li>tree.export_graphviz(estimator, out_file &#x3D; ‘tree.dot’, feature_names &#x3D; [‘’, ‘’])</li>
</ul>
</li>
</ul>
<img src="https://tonkyshan.cn/img/20250814142615.png" style="zoom:70%;" />

<p> 优点：</p>
<ul>
<li>简单的理解和解释，树木可视化</li>
</ul>
<p>缺点：</p>
<ul>
<li>决策树学习器可能会生成过于复杂的树，这些树对训练数据拟合得很好，但对新数据的推广能力很差，这种现象称为过拟合</li>
</ul>
<p>改进：</p>
<ul>
<li>减枝cart算法(决策树API当中已经实现、随机森林参数调优游相关介绍)</li>
<li>随机森林</li>
</ul>
<hr>
<h3 id="3-6-集成学习方法之随机森林"><a href="#3-6-集成学习方法之随机森林" class="headerlink" title="3.6 集成学习方法之随机森林"></a>3.6 集成学习方法之随机森林</h3><hr>
<h4 id="3-6-1-集成学习方法"><a href="#3-6-1-集成学习方法" class="headerlink" title="3.6.1 集成学习方法"></a>3.6.1 集成学习方法</h4><p>集成学习通过建立几个模型组合来解决单一预测问题。它的工作原理是<strong>生成多个分类器&#x2F;模型</strong>，各自独立地学习和做出预测。<strong>这些预测最后结合成组合预测，因此优于任何一个单分类做出的预测</strong></p>
<h4 id="3-6-2-随机森林"><a href="#3-6-2-随机森林" class="headerlink" title="3.6.2 随机森林"></a>3.6.2 随机森林</h4><p>在机器学习中，<strong>随机森林是一个包含多个决策树的分类器</strong>，并且其输出的类别是由个别树输出的类别的众数而定</p>
<h4 id="3-6-3-随机森林原理过程"><a href="#3-6-3-随机森林原理过程" class="headerlink" title="3.6.3 随机森林原理过程"></a>3.6.3 随机森林原理过程</h4><p>学习算法根据下列算法而建造每棵树：</p>
<ul>
<li>用N来表示训练用例(样本)的个数，M表示特征数目<ul>
<li>1 一次随机选出一个样本，重复N次，(有可能出现重复的样本)</li>
<li>2 随机去选出m个特征，m &lt;&lt; M，建立决策树</li>
</ul>
</li>
<li>采取bootstrap抽样</li>
</ul>
<h4 id="3-6-4-API"><a href="#3-6-4-API" class="headerlink" title="3.6.4 API"></a>3.6.4 API</h4><ul>
<li>class sklearn.ensemble.RandomForestClassifier(n_estimators &#x3D; 10, criterion &#x3D; ‘gini’, max_depth &#x3D; None, bootstrap &#x3D; True, random_state &#x3D; None, min_samples_split &#x3D; 2)<ul>
<li>随机森林分类器</li>
<li>n_estimators：integer，optional(default &#x3D; 10) 森林里的树木数量</li>
<li>criterion：string 可选(default &#x3D; ‘gini’) 分割特征的测量方法</li>
<li>max_depth：integer或None，可选(默认 &#x3D; 无) 树的最大深度 5，8，15，25，30</li>
<li>max_features &#x3D; “auto”，每个决策树的最大特征数量<ul>
<li>if “auto”, then <code>max_features = sqrt(n_features).</code></li>
<li>if “sqrt”, then <code>max_features = sqrt(n_features).</code> (same as “auto”)</li>
<li>if “log2”, then <code>max_features = log2(n_features).</code></li>
<li>if None, then <code>max_features = n_features.</code></li>
</ul>
</li>
<li>bootstrap：boolean，optional(default &#x3D; True) 是否在构建树时使用放回抽样</li>
<li>min_samples_split：节点划分最少样本数</li>
<li>min_samples_leaf：叶子节点的最少样本数</li>
</ul>
</li>
<li>超参数：n_estimators、max_depth、min_samples_split、min_samples_leaf</li>
</ul>
<hr>
<h2 id="第四章-回归与聚类算法"><a href="#第四章-回归与聚类算法" class="headerlink" title="第四章 回归与聚类算法"></a>第四章 回归与聚类算法</h2><hr>
<h3 id="4-1-线性回归"><a href="#4-1-线性回归" class="headerlink" title="4.1 线性回归"></a>4.1 线性回归</h3><hr>
<p>应用场景</p>
<ul>
<li>房价预测</li>
<li>销售额度预测</li>
<li>金融：贷款额度预测、利用线性回归以及系数分析因子</li>
</ul>
<h4 id="4-1-1什么是线性回归"><a href="#4-1-1什么是线性回归" class="headerlink" title="4.1.1什么是线性回归"></a>4.1.1什么是线性回归</h4><p>线性回归是利用<strong>回归方程(函数)<strong>对一个或</strong>多个自变量(特征值)和因变量(目标值)之间</strong>关系进行建模的一种分析方式</p>
<ul>
<li>特点：只有一个自变量的情况称为单变量回归，多于一个自变量情况的叫做多元回归</li>
</ul>
<p>公式：h(w) &#x3D; w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub> + b &#x3D; w<sup>T</sup>x + b</p>
<p>其中w，x可以理解为矩阵：<br>$$<br>\mathrm{w}&#x3D;\left(\begin{array}{c}b \ w_{1} \ w_{2}\end{array}\right), \mathrm{x}&#x3D;\left(\begin{array}{c}1 \ x_{1} \ x_{2}\end{array}\right)<br>$$</p>
<p>线性回归当中线性模型有两种，一种是线性关系，另一种是非线性关系</p>
<h4 id="4-1-2-线性回归的损失和优化原理"><a href="#4-1-2-线性回归的损失和优化原理" class="headerlink" title="4.1.2 线性回归的损失和优化原理"></a>4.1.2 线性回归的损失和优化原理</h4><p><strong>1、损失函数</strong></p>
<p>总损失定义为：<br>$$<br>J(\theta) &#x3D; (h_w(x_1) - y_1)^2 + (h_w(x_2) - y_2)^2 + \cdots + (h_w(x_m) - y_m)^2<br>          &#x3D; \sum_{i&#x3D;1}^{m} \left( h_w(x_i) - y_i \right)^2<br>$$</p>
<ul>
<li>y_i为第i个训练样本的真实值</li>
<li>h(x_i)为第i个训练样本特征值组合预测函数</li>
<li>又称最小二乘法</li>
</ul>
<p><strong>2、优化算法</strong></p>
<p>如何去求模型当中的w，使得损失最小(目的是找到最小损失对应的w值)</p>
<p>线性回归经常使用的两种优化算法</p>
<ul>
<li>正规方程</li>
</ul>
<p>​    w &#x3D; (X<sup>T</sup>X)<sup>-1</sup>X<sup>T</sup>y</p>
<p>理解：X为特征值矩阵，y为目标值矩阵，直接求到最好的结果</p>
<p>缺点：当特征过多过复杂时，求解速度太慢并且得不到结果</p>
<ul>
<li>梯度下降</li>
</ul>
<p>$$<br>\begin{array}{l}w_{1}:&#x3D;w_{1}-\alpha \frac{\partial \operatorname{cost}\left(w_{0}+w_{1} x_{1}\right)}{\partial w 1} \ w_{0}:&#x3D;w_{0}-\alpha \frac{\partial \operatorname{cost}\left(w_{0}+w_{1} x_{1}\right)}{\partial w 1}\end{array}<br>$$</p>
<blockquote>
<p>理解：α为学习速率，需要手动指定(超参数)，α旁边的整体表示方向，沿着这个函数下降的方向找，最后就能找到山谷的最低点，然后更新W值</p>
<p>使用：面对训练数据规模十分庞大的任务，能够找到较好的结果</p>
</blockquote>
<h4 id="4-1-3-线性回归API"><a href="#4-1-3-线性回归API" class="headerlink" title="4.1.3 线性回归API"></a>4.1.3 线性回归API</h4><ul>
<li>sklearn.linear_model.LinearRegression(fit_intercept &#x3D; True)<ul>
<li>通过正规方程优化</li>
<li>fit_intercept：是否计算偏置</li>
<li>LinearRegression.coef_：回归系数</li>
<li>LinearRegression.intercept_：偏置</li>
</ul>
</li>
<li>sklearn.linear_model.SGDRegressor(loss &#x3D; “squared_less”, fit_intercept &#x3D; True, learning_rate &#x3D; ‘invscaling’, eta0 &#x3D; 0.01)<ul>
<li>SGDRegressor类实现了随机梯度下降学习，它支持不同的<strong>loss函数和正则化惩罚项</strong>来拟合线性回归模型</li>
<li>loss：损失类型<ul>
<li><strong>loss &#x3D; “squared_loss”：普通最小二乘法</strong></li>
</ul>
</li>
<li>fit_intercept：是否计算偏置</li>
<li>learning_rate：string，optional<ul>
<li>学习率填充</li>
<li><strong>‘constant’：eta &#x3D; eta0</strong></li>
<li><strong>‘optimal’：eta &#x3D; 1.0 &#x2F; (alpha * (t + t0))[default]</strong></li>
<li><strong>‘invscaling’：eta &#x3D; eta0 &#x2F; pow(t, power_t)</strong><ul>
<li><strong>power_t &#x3D; 0.25：存在父类当中</strong></li>
</ul>
</li>
<li><strong>对于一个常数值的学习率来说，可以使用learning_rate &#x3D; ‘constant’，并使用eta0来指定学习率</strong></li>
</ul>
</li>
<li>SGDRegressor.coef_：回归系数</li>
<li>SGDRegressor.intercept_：偏置</li>
</ul>
</li>
</ul>
<blockquote>
<p>sklearn提供给我们两种实现的API，可以根据选择使用</p>
</blockquote>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openml
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression<span class="token punctuation">,</span> SGDRegressor

<span class="token keyword">import</span> ssl
<span class="token keyword">import</span> certifi
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

ssl<span class="token punctuation">.</span>_create_default_https_context <span class="token operator">=</span> <span class="token keyword">lambda</span><span class="token punctuation">:</span> ssl<span class="token punctuation">.</span>create_default_context<span class="token punctuation">(</span>cafile<span class="token operator">=</span>certifi<span class="token punctuation">.</span>where<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">linear1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    正规方程的优化方法对波士顿房价进行预测
    :return:
    '''</span>
    <span class="token comment"># 1）获取数据</span>
    boston <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span>name <span class="token operator">=</span> <span class="token string">'boston'</span><span class="token punctuation">,</span> version <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> as_frame <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># 2）划分数据集</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>boston<span class="token punctuation">.</span>data<span class="token punctuation">,</span> boston<span class="token punctuation">.</span>target<span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">22</span><span class="token punctuation">)</span>

    <span class="token comment"># 3）标准化</span>
    transfer <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x_train <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
    x_test <span class="token operator">=</span> transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

    <span class="token comment"># 4）预估器</span>
    estimator <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
    estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

    <span class="token comment"># 5）得出模型</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正规方程-权重系数为: \n"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正规方程-偏置为: \n"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>

    <span class="token comment"># 6）模型评估</span>
    y_predict <span class="token operator">=</span> estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测房价: \n"</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    error <span class="token operator">=</span> mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正规方程-均方误差为: \n"</span><span class="token punctuation">,</span> error<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">linear2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    梯度下降的优化方法对波士顿房价进行预测
    :return:
    '''</span>
    <span class="token comment"># 1）获取数据</span>
    boston <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span>name <span class="token operator">=</span> <span class="token string">'boston'</span><span class="token punctuation">,</span> version <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> as_frame <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># 2）划分数据集</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>boston<span class="token punctuation">.</span>data<span class="token punctuation">,</span> boston<span class="token punctuation">.</span>target<span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">22</span><span class="token punctuation">)</span>

    <span class="token comment"># 3）标准化</span>
    transfer <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x_train <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
    x_test <span class="token operator">=</span> transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

    <span class="token comment"># 4）预估器</span>
    estimator <span class="token operator">=</span> SGDRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

    <span class="token comment"># 5）得出模型</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"梯度下降-权重系数为: \n"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"梯度下降-偏置为: \n"</span><span class="token punctuation">,</span> estimator<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>

    <span class="token comment"># 6）模型评估</span>
    y_predict <span class="token operator">=</span> estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测房价: \n"</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    error <span class="token operator">=</span> mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"梯度下降-均方误差为: \n"</span><span class="token punctuation">,</span> error<span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    <span class="token comment"># 代码1：正规方程的优化方法对波士顿房价进行预测</span>
    linear1<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 代码2：梯度下降的优化方法对波士顿房价进行预测</span>
    linear2<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#正规方程 - 权重系数为:</span>
<span class="token comment"># [-0.64817766  1.14673408 - 0.05949444  0.74216553 - 1.95515269  2.70902585</span>
<span class="token comment">#  - 0.07737374 - 3.29889391  2.50267196 - 1.85679269 - 1.75044624  0.87341624</span>
<span class="token comment">#  - 3.91336869]</span>
<span class="token comment"># 正规方程 - 偏置为:</span>
<span class="token comment"># 22.621372031662272</span>
<span class="token comment"># 预测房价:</span>
<span class="token comment"># [28.22944896 31.5122308  21.11612841 32.6663189  20.0023467  19.07315705</span>
<span class="token comment">#  21.09772798 19.61400153 19.61907059 32.87611987 20.97911561 27.52898011</span>
<span class="token comment">#  15.54701758 19.78630176 36.88641203 18.81202132  9.35912225 18.49452615</span>
<span class="token comment">#  30.66499315 24.30184448 19.08220837 34.11391208 29.81386585 17.51775647</span>
<span class="token comment">#  34.91026707 26.54967053 34.71035391 27.4268996  19.09095832 14.92742976</span>
<span class="token comment">#  30.86877936 15.88271775 37.17548808  7.72101675 16.24074861 17.19211608</span>
<span class="token comment">#  7.42140081 20.0098852  40.58481466 28.93190595 25.25404307 17.74970308</span>
<span class="token comment">#  38.76446932  6.87996052 21.80450956 25.29110265 20.427491   20.4698034</span>
<span class="token comment">#  17.25330064 26.12442519  8.48268143 27.50871869 30.58284841 16.56039764</span>
<span class="token comment">#  9.38919181 35.54434377 32.29801978 21.81298945 17.60263689 22.0804256</span>
<span class="token comment">#  23.49262401 24.10617033 20.1346492  38.5268066  24.58319594 19.78072415</span>
<span class="token comment">#  13.93429891  6.75507808 42.03759064 21.9215625  16.91352899 22.58327744</span>
<span class="token comment">#  40.76440704 21.3998946  36.89912238 27.19273661 20.97945544 20.37925063</span>
<span class="token comment">#  25.3536439  22.18729123 31.13342301 20.39451125 23.99224334 31.54729547</span>
<span class="token comment">#  26.74581308 20.90199941 29.08225233 21.98331503 26.29101202 20.17329401</span>
<span class="token comment">#  25.49225305 24.09171045 19.90739221 16.35154974 15.25184758 18.40766132</span>
<span class="token comment">#  24.83797801 16.61703662 20.89470344 26.70854061 20.7591883  17.88403312</span>
<span class="token comment">#  24.28656105 23.37651493 21.64202047 36.81476219 15.86570054 21.42338732</span>
<span class="token comment">#  32.81366203 33.74086414 20.61688336 26.88191023 22.65739323 17.35731771</span>
<span class="token comment">#  21.67699248 21.65034728 27.66728556 25.04691687 23.73976625 14.6649641</span>
<span class="token comment">#  15.17700342  3.81620663 29.18194848 20.68544417 22.32934783 28.01568563</span>
<span class="token comment">#  28.58237108]</span>
<span class="token comment"># 正规方程 - 均方误差为:</span>
<span class="token comment"># 20.627513763095397</span>
<span class="token comment"># 梯度下降 - 权重系数为:</span>
<span class="token comment"># [-0.53087278  0.90066527 - 0.41998411  0.78452826 - 1.66411434  2.81985555</span>
<span class="token comment">#  - 0.1400385 - 3.06040513  1.63836989 - 0.93857943 - 1.70111028  0.86004495</span>
<span class="token comment">#  - 3.89817913]</span>
<span class="token comment"># 梯度下降 - 偏置为:</span>
<span class="token comment"># [22.63581926]</span>
<span class="token comment"># 预测房价:</span>
<span class="token comment"># [28.3384972  31.61218432 21.46396158 32.65581505 20.30729174 19.10061829</span>
<span class="token comment">#  21.38069526 19.53714795 19.75519481 32.800326   21.36875982 27.27413464</span>
<span class="token comment">#  15.63267453 19.98927317 36.99754756 18.67182959  9.69770926 18.70124007</span>
<span class="token comment">#  30.83563162 24.33599091 19.06795404 34.05033349 29.50094527 17.39985907</span>
<span class="token comment">#  34.80737074 26.48659296 34.31171118 27.41944575 19.08627983 15.87222231</span>
<span class="token comment">#  30.79178744 14.51153831 37.45078101  8.67125435 16.46208808 16.83277864</span>
<span class="token comment">#  7.68156071 19.80748244 40.48142444 29.2664118  25.31618817 17.8572737</span>
<span class="token comment">#  39.25712808  6.68761008 21.56415312 25.05111149 20.88999669 20.69732958</span>
<span class="token comment">#  17.02796236 26.26659763  9.66659845 27.17979966 30.62987402 16.65438921</span>
<span class="token comment">#  9.58865169 35.4414963  31.47834199 22.986851   17.64076732 21.95875243</span>
<span class="token comment">#  23.64418027 23.96574351 20.44045063 38.17989465 25.74351719 19.66462643</span>
<span class="token comment">#  14.15722486  6.66995377 42.40651742 21.89014826 16.70608227 22.7040728</span>
<span class="token comment">#  40.88428941 21.79554256 36.87164444 27.16304009 21.95214659 20.7841799</span>
<span class="token comment">#  25.38449507 23.84834719 31.51118485 20.25375911 23.99097276 31.4576435</span>
<span class="token comment">#  27.23684728 20.89030294 29.06532415 22.1043287  26.74748695 18.82579376</span>
<span class="token comment">#  25.18329361 23.9334069  19.94497257 17.6087464  15.47370814 18.30864154</span>
<span class="token comment">#  24.58487929 16.74665111 20.65366946 26.82001204 20.67787656 17.98854794</span>
<span class="token comment">#  24.13807094 23.27245058 20.34099272 36.49425084 16.10123196 22.49570103</span>
<span class="token comment">#  32.66186733 33.62779611 20.61225142 25.97666765 23.30780317 17.74838749</span>
<span class="token comment">#  21.55604458 21.82380492 27.54772173 25.30744437 23.6853392  14.44559773</span>
<span class="token comment">#  15.61858598  3.65291912 29.24019186 20.68377264 22.34013216 28.08768094</span>
<span class="token comment">#  28.35643226]</span>
<span class="token comment"># 梯度下降 - 均方误差为:</span>
<span class="token comment"># 21.17625015763062</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p><strong>分析</strong></p>
<p>回归当中的数据大小不一致，是否会导致结果影响较大。所以需要做标准化处理</p>
<ul>
<li>数据分割与标准化处理</li>
<li>回归预测</li>
<li>线性回归的算法效果评估</li>
</ul>
<p><strong>回归性能评估</strong></p>
<p>均方误差(Mean Squared Error) MSE评价机制<br>$$<br>M S E&#x3D;\frac{1}{m} \sum_{i&#x3D;1}^{m}\left(y^{i}-\bar{y}\right)^{2}<br>$$</p>
<blockquote>
<p>tips：y<sup>i</sup>为预测值，ȳ为真实值</p>
</blockquote>
<ul>
<li>sklearn.metrics.mean_squared_error(y_true, y_pred)<ul>
<li>均方误差回归损失</li>
<li>y_true：真实值</li>
<li>y_pred：预测值</li>
<li>return：浮点数结果</li>
</ul>
</li>
</ul>
<p><strong>对比</strong></p>
<table>
<thead>
<tr>
<th align="center">梯度下降</th>
<th align="center">正规方程</th>
</tr>
</thead>
<tbody><tr>
<td align="center">需要选择学习率</td>
<td align="center">不需要</td>
</tr>
<tr>
<td align="center">需要迭代求解</td>
<td align="center">一次运算得出</td>
</tr>
<tr>
<td align="center">特征数量较大可以使用</td>
<td align="center">需要计算方程，时间复杂度高O(n<sup>3</sup>)</td>
</tr>
</tbody></table>
<p>选择：</p>
<ul>
<li>小规模数据：<ul>
<li><strong>LinearRegression(不能解决拟合问题)</strong></li>
<li>岭回归</li>
</ul>
</li>
<li>大规模数据：<ul>
<li>SGDRegressor</li>
</ul>
</li>
</ul>
<p>扩展-关于优化方法GD、SGD、SAG</p>
<p>1、GD</p>
<p>梯度下降，原始的梯度下降法需要计算所有样本的值才能够得出梯度，计算量大，所以后面才会有一系列的改进</p>
<p>2、SGD</p>
<p>随机梯度下降，是一个优化方法，它在一次迭代时只考虑一个训练样本</p>
<ul>
<li>SGD的优点是：<ul>
<li>高效</li>
<li>容易实现</li>
</ul>
</li>
<li>SGD的缺点是：<ul>
<li>SGD需要许多超参数：比如正则项参数、迭代数</li>
<li>SGD对于特征标准化是敏感的</li>
</ul>
</li>
</ul>
<p>3、SAG</p>
<p>随机平均梯度法，由于收敛的速度太慢，有人提出SAG等基于梯度下降的算法</p>
<p>Scikit-learn：岭回归、逻辑回归等当中都会有SAG优化</p>
<hr>
<h3 id="4-2-欠拟合与过拟合"><a href="#4-2-欠拟合与过拟合" class="headerlink" title="4.2 欠拟合与过拟合"></a>4.2 欠拟合与过拟合</h3><hr>
<p>欠拟合：一个假设在训练数据上不能获得更好的拟合，并且在测试数据集上却不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象(模型过于简单)</p>
<p>过拟合：一个假设在训练数据上能够获得比其他假设更好的拟合，但是在测试数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合的现象(模型过于复杂)</p>
<p><strong>原因以及解决办法</strong></p>
<ul>
<li>欠拟合原因以及解决办法<ul>
<li>原因：学习到数据的特征过少</li>
<li>解决办法：增加数据的特征数量</li>
</ul>
</li>
<li>过拟合原因以及解决办法<ul>
<li>原因：原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点</li>
<li>解决办法：正则化</li>
</ul>
</li>
</ul>
<h4 id="4-2-1-正则化类别"><a href="#4-2-1-正则化类别" class="headerlink" title="4.2.1 正则化类别"></a>4.2.1 正则化类别</h4><p><strong>1、L2正则化</strong></p>
<ul>
<li>作用：可以使得其中的一些W都很小，都接近于0，削弱某个特征的影响</li>
<li>优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象</li>
<li>Ridge回归</li>
<li>加入L2正则化后的损失函数</li>
</ul>
<p>$$<br>J(w)&#x3D;\frac{1}{2 m} \sum_{i&#x3D;1}^{m}\left(h_{w}\left(x_{i}\right)-y_{i}\right)^{2}+\lambda \sum_{j&#x3D;1}^{n} w_{j}^{2}<br>$$</p>
<blockquote>
<p>tips：m为样本数，n为特征数</p>
</blockquote>
<p><strong>2、L1正则化</strong></p>
<ul>
<li>作用：可以使得其中的一些值直接为0，删除这个特征的影响</li>
<li>LASSO回归</li>
</ul>
<hr>
<h3 id="4-3-线性回归的改进-岭回归"><a href="#4-3-线性回归的改进-岭回归" class="headerlink" title="4.3 线性回归的改进-岭回归"></a>4.3 线性回归的改进-岭回归</h3><hr>
<hr>
<h3 id="4-4-分类算法-逻辑回归与二分类"><a href="#4-4-分类算法-逻辑回归与二分类" class="headerlink" title="4.4 分类算法-逻辑回归与二分类"></a>4.4 分类算法-逻辑回归与二分类</h3><hr>
<hr>
<h3 id="4-5-模型保存和加载"><a href="#4-5-模型保存和加载" class="headerlink" title="4.5 模型保存和加载"></a>4.5 模型保存和加载</h3><hr>
<hr>
<h3 id="4-6-无监督学习-K-means算法"><a href="#4-6-无监督学习-K-means算法" class="headerlink" title="4.6 无监督学习-K-means算法"></a>4.6 无监督学习-K-means算法</h3><hr>
<hr>
<h3 id="4-7-总结"><a href="#4-7-总结" class="headerlink" title="4.7 总结"></a>4.7 总结</h3><hr>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>ShanTianQi</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://tonkyshan.cn/2025/07/31/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/">https://tonkyshan.cn/2025/07/31/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="../../../../tags/Python/"># Python</a>
                    
                        <a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"># 机器学习</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="../../../10/10/Kafka/">Kafka</a>
            
            
            <a class="next" rel="next" href="../../14/numpy-pandas-matplotlib/">Numpy + Pandas + Matplotlib</a>
            
        </section>


    </article>
</div>

            </div>
            <!-- <!--<footer id="footer" class="footer">
    <div class="copyright">
        <span>© ShanTianQi | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>
 -->
    </div>
</body>

</html>